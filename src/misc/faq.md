## FAQ

![](images/2-aigc-investment.png)

### 企业 AIGC 投资策略

不同的企业，应该根据自身的情况（安全、隐私等等），来调整自己的投资策略。

而随着时间的演讲，也会出现越来越多的新场景，带来不同的变化。

### LLM 研发效能的提效？

- xxx 公司 CTO： 显著缩短 1 年工作经验和 3 年工作经验的差距。
- LLM 报告，综合 Copliot 研究结果：
    - 自动化测试提升 ~60%，通用型业务代码（CRUD）实现提升 ~35%，其它非通用型代码（如云基础设施）提升10-20%
    - 提升难点：依赖于开发人员「套路化设计」能力，如拆分任务、多个小的函数。

### LLM 提效试验如何设计？

**基于已有流程设计**

将流程中的某些环节替换为 LLM，然后对比效果。

![](images/llm-sdlc-processes.png)

对比方式： 选择某个项目作为试点，进行时间评估与对比。

**基于新流程与已有数据设计**

// TODO

### ROI 验证

**从效能角度看**
对比方式： 选择某个项目作为试点，选择多个研发效能指标（比如需求吞吐量、代码变更量等），历经多个迭代后，进行指标值对比。

**从人员角度看**
对比方式： 选择某个组织作为试点，在效能要求保持不变的前提下，历经一段时间（比如三个月），看所需人员的数量变化（比如100->90)

**从财务角度看**
对比方式： LLM基础设施搭建+推广+培训等成本，与降下来的人员成本做比对

// TODO 还需增加角度并完善内容实验

### Prompt 工程是否有未来？

在探讨工程是否有未来之前，我们先了解一下狭义和广义的 Prompt 工程。

**狭义的 Prompt 工程**专注于 AI 领域的 Prompt
优化，即通过优化任务描述来提高自然语言处理模型的性能。典型的做法是将一个或多个任务转换为基于提示的数据集，并通过所谓的“基于提示的学习”来训练语言模型。这有助于训练大型语言模型 (
LLM)，使 AI 能更好地理解需求并完成专业任务。

**广义的 Prompt 工程师**则是指针对 AI 模型编写 Prompt 的人，以获得更好的结果。他们需要找到合适的提示词，让 AI
发挥出最大潜力。这个角色可以分为两部分：面向大语言模型的工程师和面向落地应用的工程师。

**从使用 AI 模型的角度看**。随着 AI 技术的发展和普及，对 AI 模型的需求可能会逐渐减弱。这是因为随着模型的不断优化，它们的理解能力和性能将不断提高，使得在许多情况下无需额外的
Prompt 工程即可满足需求。然而，这并不意味着 Prompt 工程没有未来。相反，随着 AI 在越来越多的领域得到应用，Prompt
工程仍然可以为特定任务和领域提供有针对性的优化。

**从工程侧的角度看**。大型公司可能需要一两位专家来指导开发人员进行 Prompt 工程。通过组织活动（如 hackathon），公司可以提高开发人员对
Prompt
工程的意识，帮助他们结合 Prompt 开发应用，以实现工程化落地。尽管大部分开发人员可能还没有充分认识到 Prompt
工程的重要性，但随着时间的推移，这一情况有望得到改善。

**结论**

综上所述，工程在狭义和广义上都有一定的未来。尽管随着 AI 技术的进步，使用 AI 模型的需求可能会逐渐减弱，但 Prompt
工程仍然可以为特定任务和领域提供有针对性的优化。此外，大型公司需要专家指导开发人员进行 Prompt 工程，提高他们的意识并实现工程化落地。因此，Prompt
工程在未来仍然具有一定的发展空间和潜力。

同时我们看到，很多企业的AI2.0起步都将从Prompt工程开始，不同行业不同的融入节奏下，会使得Prompt工程在未来很长一段时间内都很重要。

### Prompt 工程师会有未来吗？

有，Prompt 工程师在未来会更像是一个 Prompt 教练、专家的角色，他们会帮助开发者更好地使用 Prompt。

### 什么时候考虑微调？

微调（fine-tuning）通常是在已经预训练好的模型的基础上，使用特定的数据集进行进一步训练，以适应特定的任务或应用场景。通常情况下，微调会在以下情况下进行考虑：

1. 适应特定的任务或领域：预训练的模型通常是在大规模通用语料库上进行训练的，而在特定的任务或领域中，可能需要使用更具体的语言模式和领域知识。这时候，就需要使用微调的方式对模型进行进一步训练，以适应特定的任务或领域。
2. 数据集与预训练数据的差异较大：如果预训练的模型的训练数据与实际应用场景的数据差异较大，那么使用微调的方式可以更好地适应实际场景的数据分布，提高模型的性能。
3. 进一步提高模型的性能：在一些对模型性能要求较高的任务中，使用微调的方式可以进一步提高模型的性能，从而更好地满足实际应用需求。

然而，ChatGPT 总结的并不好，当你要考虑微调的时候，你应该考虑的是：

1. ROI。微调的成本是很高的 —— 准备数据、训练模型、调参、部署，并进行持续的模型优化。
2. 好的基础模型。如果你的基础模型不够好，微调也不会有很好的效果。诸如于 LLaMA 7B 的中文效果不好。
3. 工程能力。微调的过程中，你需要有很好的工程能力，包括数据处理、模型训练、模型部署等等。

除此，在你没有思考清楚上述三点的时候，你不应该考虑微调。

### 个人的策略？

对于我来说，我的 AI 策略大致是：

1. 拥抱变化，尽管人工智能并不能完全代替人类，但它已经能够大大提高效率。
2. 强化构架能力，因为人工智能工具无法代替个人的感性思考和直觉。
3. 构建领域小模型，可以快速训练出一个专门用于解决自己问题的小型模型。
4. 探索与磨炼技巧，探索 AI 能力并持续构建小工具，来修复和完善自己的 AI 增强系统。

对于修复与完善来说，由于 AI 本身是无法达到这么精细的，所以我的想法是**持续构建小工具**。
